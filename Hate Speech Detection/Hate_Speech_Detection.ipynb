{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hate Speech Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import all necessary Python Libraries and Dataset"
      ],
      "metadata": {
        "id": "gyl3CmFkIkyj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "eby2nq580UQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b543b7-4c11-4a06-fbe0-3debd0630e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0           0      3            0                   0        3      2   \n",
            "1           1      3            0                   3        0      1   \n",
            "2           2      3            0                   3        0      1   \n",
            "3           3      3            0                   2        1      1   \n",
            "4           4      6            0                   6        0      1   \n",
            "\n",
            "                                               tweet  \n",
            "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
            "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
            "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
            "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
            "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "from nltk.util import pr\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "stemmer = nltk.SnowballStemmer('english')\n",
        "stopword = set(stopwords.words('english'))\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/juniarta-rendy/Website-data/master/twitter.csv\")\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add new Column named Labels"
      ],
      "metadata": {
        "id": "OvnHNCThLrdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['labels'] = data['class'].map({0:'Hate Speech', 1:'Offensive Language', 2:'No Hate and Offensive'})\n",
        "\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc4zg3r1K9jq",
        "outputId": "5de20b9b-8e05-4351-bf7e-c9fd88708900"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0           0      3            0                   0        3      2   \n",
            "1           1      3            0                   3        0      1   \n",
            "2           2      3            0                   3        0      1   \n",
            "3           3      3            0                   2        1      1   \n",
            "4           4      6            0                   6        0      1   \n",
            "\n",
            "                                               tweet                 labels  \n",
            "0  !!! RT @mayasolovely: As a woman you shouldn't...  No Hate and Offensive  \n",
            "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...     Offensive Language  \n",
            "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...     Offensive Language  \n",
            "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...     Offensive Language  \n",
            "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...     Offensive Language  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['tweet','labels']]\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm-IrjzcLmg2",
        "outputId": "f1e8d82c-e4f2-44b3-9a66-de1d51720505"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet                 labels\n",
            "0  !!! RT @mayasolovely: As a woman you shouldn't...  No Hate and Offensive\n",
            "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...     Offensive Language\n",
            "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...     Offensive Language\n",
            "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...     Offensive Language\n",
            "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...     Offensive Language\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "function to Clean the text in Tweet column"
      ],
      "metadata": {
        "id": "gJcpEFo_MM-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(text):\n",
        "  text = str(text.lower())\n",
        "  text = re.sub('\\[.*?\\]', '',text)\n",
        "  text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "  text = re.sub('<.*?>+', '', text)\n",
        "  text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "  text = re.sub('\\n', '', text)\n",
        "  text = re.sub('\\w*\\d\\w*', '', text)\n",
        "  text = [word for word in text.split(' ') if word not in stopword]\n",
        "  text=\" \".join(text)\n",
        "  text = [stemmer.stem(word) for word in text.split(' ')]\n",
        "  text=\" \".join(text)\n",
        "  return text\n",
        "\n",
        "data['tweet'] = data['tweet'].apply(clean)\n",
        "print(data['tweet'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFcV4NkdL9fD",
        "outputId": "da7f9624-1578-4059-95bb-dbf8119443b9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     rt mayasolov woman shouldnt complain clean ho...\n",
            "1     rt  boy dat coldtyga dwn bad cuffin dat hoe  ...\n",
            "2     rt urkindofbrand dawg rt  ever fuck bitch sta...\n",
            "3               rt cganderson vivabas look like tranni\n",
            "4     rt shenikarobert shit hear might true might f...\n",
            "Name: tweet, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split dataset into Train and Test and Train the Machine Learning Model"
      ],
      "metadata": {
        "id": "JqjkuSuDOrWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(data['tweet'])\n",
        "y = np.array(data['labels'])\n",
        "\n",
        "cv = CountVectorizer()\n",
        "#fit the data\n",
        "X = cv.fit_transform(x)\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(x_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBREM9rQOfSU",
        "outputId": "1037a703-f319-4ed0-fce3-4cc1b132c0f5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = input('Enter a text: ')\n",
        "data = cv.transform([sample]).toarray()\n",
        "print(clf.predict(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX44b2v6P1sI",
        "outputId": "bab302bf-d535-4eed-f40d-b9443d63b80c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a text: Let's unite and kill all the people who are protesting against the government\n",
            "['Hate Speech']\n"
          ]
        }
      ]
    }
  ]
}